# coding: utf8

from __future__ import unicode_literals, print_function
import unittest
from efc.rpn import tokens
from efc.rpn.lexer import Lexer
from itertools import product, chain, izip
import six


class TestToken(object):
    def __init__(self, cls, v):
        self.cls = cls
        self.v = v


class LexerTestCase(unittest.TestCase):
    def setUp(self):
        self.token_examples = {
            tokens.FloatToken: [2345.234],
            tokens.IntToken: [2345],
            tokens.StringToken: ['"test"'],
            tokens.NameToken: ['my_name', ],
            tokens.CellRangeToken: ['B4:M1', 'HH1:LLS3', '$HH$1:$LLS$3'],
            tokens.CellAddressToken: ['B4', '$B4', 'B$4', '$B$4'],
            tokens.SheetNameToken: ['List1!', '\'List 2\'!']
        }

        self.separators = {
            tokens.ArithmeticToken: ['+', '-', '/', '*', '&', '^'],
            tokens.CompareToken: ['<', '>', '>=', '<=', '=', '<>'],
            tokens.LeftBracketToken: ['('],
            tokens.RightBracketToken: [')'],
            tokens.SpaceToken: [' ', ' ', '   '],
        }
        self.lexer = Lexer()

    def test_all_combinations(self):
        examples = [map(lambda e: TestToken(eg_cls, e), eg)
                    for eg_cls, eg in six.iteritems(self.token_examples)]

        for sep_cls, sep in six.iteritems(self.separators):
            test_sep = [TestToken(sep_cls, s) for s in sep]

            to_comb = [[eg, test_sep] for eg in examples]
            to_comb[-1].pop(1)

            for comb in product(*chain(*to_comb)):
                cleaned_values, values, tokens_cls = [], [], []
                for item in comb:
                    values.append(item.v)
                    if item.cls != tokens.SpaceToken:
                        tokens_cls.append(item.cls)
                        cleaned_values.append(item.v)

                autogenerated_line = ''.join((str(v) for v in values))

                parsed_tokens_line = self.lexer.parse(autogenerated_line)

                parsed_tokens_cls = [i.__class__ for i in parsed_tokens_line]
                self.assertListEqual(tokens_cls, parsed_tokens_cls)

                reconstructed_line = ''.join(t.src_value
                                             for t in parsed_tokens_line)
                target_line = ''.join((str(v) for v in cleaned_values))
                self.assertEqual(reconstructed_line, target_line)
